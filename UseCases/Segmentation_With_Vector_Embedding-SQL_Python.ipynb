{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<header>\n",
    "   <p  style='font-size:36px;font-family:Arial; color:#F0F0F0; background-color: #00233c; padding-left: 20pt; padding-top: 20pt;padding-bottom: 10pt; padding-right: 20pt;'>\n",
    "       Optimize Customer Segmentation using ClearScape Analytic Functions and Open-Source LLMs\n",
    "  <br>\n",
    "       <img id=\"teradata-logo\" src=\"https://raw.githubusercontent.com/Teradata/lake-demos/8c77e9297e8f3059921aee472fc0ae30ae0537db/images/TeradataLogo.png\" alt=\"Teradata\" style=\"width: 125px; height: auto; margin-top: 20pt;\">\n",
    "    </p>\n",
    "</header>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<b style = 'font-size:24px;font-family:Arial;color:#00233C'>Leverage highly-scalable native processing functions to create ideal customer segments using word embeddings and clustering algorithms</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Vector embedding</b> is a numerical representation of data that captures semantic relationships and similarities, making it possible to perform mathematical operations and comparisons on the data for various tasks like text analysis and recommendation systems.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>K-means clustering</b> is one of the most popular <b>unsupervised</b> machine learning algorithms.  Essentially, the algorithm seeks to group similar data points together by minimizing the average (\"means\" in K-means) distance for all data points from each cluster's center (centroid).</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Using <b>Teradata Vantage</b> and <b>ClearScape Analytics</b>, we can combine these advanced AI and ML techniques to <b>rapidly</b> find the ideal number of customer segments based on the semantic meaning of their comments history.  This segmentation can be used on its own for marketing and other tasts, or used in further predictive analytics use cases.</p>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '50%'>\n",
    "            <ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "                <li>Create a Vector Embedding table using open-source LLMs against customer comments data, using the <b>AI Unlimited</b> Engine</li>\n",
    "                <br>\n",
    "                <li>Execute multiple experiments <b>in parallel</b>, leveraging the highly-scalable nature of the platform<</li>\n",
    "                <br>\n",
    "                <li>Visualize the experimental results to indicate the best cluster</li>\n",
    "            </ol>\n",
    "        </td>\n",
    "        <td><img src = 'https://raw.githubusercontent.com/Teradata/lake-demos/8c77e9297e8f3059921aee472fc0ae30ae0537db/UseCases/Vector-Embeddings-Segmentation/images/comparative_superlative_small.jpg' width = '250'></td>\n",
    "        <td><img src = 'https://raw.githubusercontent.com/Teradata/lake-demos/8c77e9297e8f3059921aee472fc0ae30ae0537db/UseCases/Vector-Embeddings-Segmentation/images/K-means_convergence.gif' width = '250'></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Step 0 - Access and inspect data</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Teradata AI Unlimited can transparently <b>read</b> and <b>write</b> data from various third-party catalogs such as <b>AWS Glue</b>, <b>Azure OneLake</b>, etc.  To access this data, perform the following</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Install any prerequisite python packages</li>\n",
    "    <li>Create an Authorization object for secured access</li>\n",
    "    <li>Create a \"DATALAKE\" object that points to the catalog</li>\n",
    "    <li>Use SQL syntax to inspect the catalog, database, and table metadata</li>\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install ipython-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql\n",
    "%sql teradatasql://tduser:teradata@unlimited/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/*First, we'll create an authorization to establish the credendials for AWS resources */\n",
    "REPLACE AUTHORIZATION unlimited.glue_auth_aws\n",
    "USER 'EXAMPLE'\n",
    "PASSWORD 'EXAMPLE';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "/*Second we create the connectivity to the Iceberg Glue Data Lake*/\n",
    "\n",
    "REPLACE DATALAKE aws_glue_catalog\n",
    "EXTERNAL SECURITY CATALOG unlimited.glue_auth_aws,\n",
    "EXTERNAL SECURITY STORAGE unlimited.glue_auth_aws\n",
    "USING\n",
    "catalog_type ('glue')\n",
    "storage_region ('us-west-2')\n",
    "TABLE FORMAT iceberg;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql HELP DATALAKE aws_glue_catalog;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql HELP DATABASE aws_glue_catalog.tddemos_glue_db;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql HELP TABLE aws_glue_catalog.tddemos_glue_db.web_comment;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Step 1 - Data Preparation using an LLM to create a Vector Table</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Here, we will inspect the original data set, and use native vector embedding functions to generate features.  This data has been pre-loaded in an AWS Glue catalog.  Users can access this data transparently using multi-dot notation.</p>\n",
    "\n",
    "<ol style = 'font-size:16px;font-family:Arialcolor:#00233C'>\n",
    "    <li>Inspect the rows of the Customer Comments table</li>\n",
    "    <li>Inspect the GloVe Model table</li>\n",
    "    <li>Use TD_WordEmbeddings function to create the vector table</li>\n",
    "    </ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>1.1 - Inspect the Data</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arialcolor:#00233C'>Display a sample</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM aws_glue_catalog.tddemos_glue_db.web_comment\n",
    "SAMPLE 2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233'>1.2 - Model table</b>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>We format the model table as in the documentation: a column for the token, and a column for each dimension of the vector space. This example uses the GloVe 50-dimensional pre-trained embeddings. For more information on this model, see the Stanford University Publication <a href = 'https://nlp.stanford.edu/projects/glove/'>\"GloVe: Global Vectors for Word Representation\"</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM aws_glue_catalog.tddemos_glue_db.glove_6B_50d\n",
    "SAMPLE 2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>1.4 - Embeddings</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>TD_WordEmbeddings can perform four operations: token-embedding, doc-embedding, token2token-similarity, and doc2doc-similarity. This notebook shows the first two.  We will use doc-embedding as the basis for our Segmentation.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH comments_data AS (\n",
    "    SELECT comment_id, customer_id, TRANSLATE(comment_text USING UNICODE_TO_LATIN) comment_text\n",
    "    FROM aws_glue_catalog.tddemos_glue_db.web_comment),\n",
    "\n",
    "model_data AS (\n",
    "    SELECT TRANSLATE(doc_id USING UNICODE_TO_LATIN) doc_id, \n",
    "            v1, v2, v3, v4, v5, v6, v7, v8, v9, v10, \n",
    "            v11, v12, v13, v14, v15, v16, v17, v18, v19, v20, \n",
    "            v21, v22, v23, v24, v25, v26, v27, v28, v29, v30, \n",
    "            v31, v32, v33, v34, v35, v36, v37, v38, v39, v40, \n",
    "            v41, v42, v43, v44, v45, v46, v47, v48, v49, v50\n",
    "    FROM aws_glue_catalog.tddemos_glue_db.glove_6B_50d)\n",
    "    \n",
    "\n",
    "SELECT TOP 5 * FROM TD_WordEmbeddings (\n",
    "    ON (SELECT TOP 1 * FROM comments_data) AS InputTable\n",
    "    ON model_data AS ModelTable DIMENSION\n",
    "USING\n",
    "    IDColumn('comment_id')\n",
    "    ModelVectorColumns('[1:49]')\n",
    "    PrimaryColumn('comment_text')\n",
    "    Operation('token-embedding')\n",
    "    ModelTextColumn('doc_id')\n",
    ")AS dt \n",
    "ORDER BY comment_id ASC;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "WITH comments_data AS (\n",
    "    SELECT TOP 1000 comment_id, customer_id, TRANSLATE(comment_text USING UNICODE_TO_LATIN) comment_text\n",
    "    FROM aws_glue_catalog.tddemos_glue_db.web_comment),\n",
    "\n",
    "model_data AS (\n",
    "    SELECT TRANSLATE(doc_id USING UNICODE_TO_LATIN) doc_id, v1, v2, v3, v4\n",
    "            v5, v6, v7, v8, v9, v10,\n",
    "            v11, v12, v13, v14, v15,\n",
    "            v16, v17, v18, v19, v20,\n",
    "            v21, v22, v23, v24, v25,\n",
    "            v26, v27, v28, v29, v30,\n",
    "            v31, v32, v33, v34, v35,\n",
    "            v36, v37, v38, v39, v40,\n",
    "            v41, v42, v43, v44, v45,\n",
    "            v46, v47, v48, v49, v50\n",
    "    FROM aws_glue_catalog.tddemos_glue_db.glove_6B_50d)\n",
    "\n",
    "SELECT TOP 2 * FROM TD_WordEmbeddings (\n",
    "    ON comments_data AS InputTable\n",
    "    ON model_data AS ModelTable DIMENSION\n",
    "USING\n",
    "    IDColumn('comment_id')\n",
    "    ModelVectorColumns('[1:49]')\n",
    "    PrimaryColumn('comment_text')\n",
    "    Operation('doc-embedding')\n",
    "    ModelTextColumn('doc_id')\n",
    "    Accumulate('comment_text', 'customer_id')\n",
    ")AS dt \n",
    "ORDER BY comment_id ASC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>1.4 - Materialize the data</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Materialize the embeddings to a local table for consistency and performance - no need to re-embed each experiment.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "/*Drop the table if necessary.  We are using volatile tables, \n",
    "so this shouldn't be necessary unless we rerun this in the same session */\n",
    "DROP TABLE embedded_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE MULTISET VOLATILE TABLE embedded_data AS(\n",
    "    WITH comments_data AS (\n",
    "        SELECT TOP 1000 comment_id, customer_id, TRANSLATE(comment_text USING UNICODE_TO_LATIN) comment_text\n",
    "        FROM aws_glue_catalog.tddemos_glue_db.web_comment),\n",
    "    \n",
    "    model_data AS (\n",
    "        SELECT TRANSLATE(doc_id USING UNICODE_TO_LATIN) doc_id, v1, v2, v3, v4\n",
    "                v5, v6, v7, v8, v9, v10,\n",
    "                v11, v12, v13, v14, v15,\n",
    "                v16, v17, v18, v19, v20,\n",
    "                v21, v22, v23, v24, v25,\n",
    "                v26, v27, v28, v29, v30,\n",
    "                v31, v32, v33, v34, v35,\n",
    "                v36, v37, v38, v39, v40,\n",
    "                v41, v42, v43, v44, v45,\n",
    "                v46, v47, v48, v49, v50\n",
    "        FROM aws_glue_catalog.tddemos_glue_db.glove_6B_50d)\n",
    "    \n",
    "    SELECT * FROM TD_WordEmbeddings (\n",
    "        ON comments_data AS InputTable\n",
    "        ON model_data AS ModelTable DIMENSION\n",
    "    USING\n",
    "        IDColumn('comment_id')\n",
    "        ModelVectorColumns('[1:49]')\n",
    "        PrimaryColumn('comment_text')\n",
    "        Operation('doc-embedding')\n",
    "        ModelTextColumn('doc_id')\n",
    "        Accumulate('comment_text', 'customer_id')\n",
    "    )AS dt \n",
    ")WITH DATA\n",
    "NO PRIMARY INDEX\n",
    "ON COMMIT PRESERVE ROWS;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Step 2 - Find the Ideal K-means Model</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>As discussed above, the K-means algorithm takes a number of clusters \"k\", chooses a random starting point for each centroid, and iterates until a hard limit or an optimium value is reached.</p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'><b>Other Function Parameters Include (but are not limited to)</b></p>\n",
    "<ul style = 'font-size:16px;font-family:Arial;color:#00233C'>\n",
    "    <li>Input data - table, view, query</li>\n",
    "    <li>StopThreshold - The algorithm converges if the distance between the centroids from the previous iteration and the current iteration is less than the specified value.</li>\n",
    "    <li>MaxIterNum</li>Specify the maximum number of iterations for the K-means algorithm. The algorithm stops after performing the specified number of iterations even if the convergence criterion is not met.\n",
    "    </ul>\n",
    "    \n",
    "<hr>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>2.1 - Example Model - 4-cluster test</b>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>The example below uses an arbitrary number of clusters to create the first model.  Note the output metadata provides information such as the number of iterations, converged or not, etc.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT td_clusterid_kmeans, td_size_kmeans, td_withinss_kmeans, td_modelinfo_kmeans \n",
    "FROM TD_KMeans (\n",
    "    ON embedded_data AS InputTable \n",
    "USING\n",
    "    IdColumn('comment_id') \n",
    "    TargetColumns('[1:49]') \n",
    "    NumClusters(4)\n",
    "    StopThreshold(0.0295) \n",
    "    MaxIterNum(10)\n",
    ")AS dt;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style = 'font-size:18px;font-family:Arial;color:#00233C'>2.2 - Finding an Ideal value for K</b>\n",
    "\n",
    "<table style = 'width:100%;table-layout:fixed;'>\n",
    "    <tr>\n",
    "        <td style = 'vertical-align:top' width = '50%'>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>Typically, data scientists will build the model using various values for \"k\", and plot the \"WCSS\" (Within Cluster Sum-of-Squares) value on a series of each value chosen for k.  The \"elbow\" point (where the slope changes) is usually a good value for k.  <a href = 'https://docs.teradata.com/r/Teradata-VantageTM-Analytics-Database-Analytic-Functions-17.20/Model-Training-Functions/TD_KMeans'>KMeans</a> function will return this value as \"TotalWithinSS : ###\" as a row in the \"td_modelinfo_kmeans\" column.</p>\n",
    "<br>\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>In the below example, we will express this function using values from 2 to 8 for \"k\".  Due to the highly-scalable nature of the native training function, we can perform this analysis incredibly rapidly and in parallel.</p>\n",
    "        </td>\n",
    "        <td><img src = 'https://raw.githubusercontent.com/Teradata/lake-demos/8c77e9297e8f3059921aee472fc0ae30ae0537db/UseCases/Vector-Embeddings-Segmentation/images/WCSS_elbow.png' width = '300'></td>\n",
    "    </tr>\n",
    "    </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT '2' as K, SUM(td_withinss_kmeans) as SUM_WITHINSS FROM TD_KMeans (\n",
    "    ON embedded_data AS InputTable \n",
    "USING\n",
    "    IdColumn('comment_id') \n",
    "    TargetColumns('[1:49]') \n",
    "    NumClusters(2)\n",
    "    StopThreshold(0.0295) \n",
    "    MaxIterNum(10)\n",
    ")AS dt\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT '3' as K, SUM(td_withinss_kmeans) as SUM_WITHINSS FROM TD_KMeans (\n",
    "    ON embedded_data AS InputTable \n",
    "USING\n",
    "    IdColumn('comment_id') \n",
    "    TargetColumns('[1:49]') \n",
    "    NumClusters(3)\n",
    "    StopThreshold(0.0295) \n",
    "MaxIterNum(10)\n",
    ")AS dt\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT '4' as K, SUM(td_withinss_kmeans) as SUM_WITHINSS FROM TD_KMeans (\n",
    "    ON embedded_data AS InputTable \n",
    "USING\n",
    "    IdColumn('comment_id') \n",
    "    TargetColumns('[1:49]') \n",
    "    NumClusters(4)\n",
    "    StopThreshold(0.0295) \n",
    "MaxIterNum(10)\n",
    ")AS dt\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT '5' as K, SUM(td_withinss_kmeans) as SUM_WITHINSS FROM TD_KMeans (\n",
    "    ON embedded_data AS InputTable \n",
    "USING\n",
    "    IdColumn('comment_id') \n",
    "    TargetColumns('[1:49]') \n",
    "    NumClusters(5)\n",
    "    StopThreshold(0.0295) \n",
    "MaxIterNum(10)\n",
    ")AS dt\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT '6' as K, SUM(td_withinss_kmeans) as SUM_WITHINSS FROM TD_KMeans (\n",
    "    ON embedded_data AS InputTable \n",
    "USING\n",
    "    IdColumn('comment_id') \n",
    "    TargetColumns('[1:49]') \n",
    "    NumClusters(6)\n",
    "    StopThreshold(0.0295) \n",
    "MaxIterNum(10)\n",
    ")AS dt\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT '7' as K, SUM(td_withinss_kmeans) as SUM_WITHINSS FROM TD_KMeans (\n",
    "    ON embedded_data AS InputTable \n",
    "USING\n",
    "    IdColumn('comment_id') \n",
    "    TargetColumns('[1:49]') \n",
    "    NumClusters(7)\n",
    "    StopThreshold(0.0295) \n",
    "MaxIterNum(10)\n",
    ")AS dt\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT '8' as K, SUM(td_withinss_kmeans) as SUM_WITHINSS FROM TD_KMeans (\n",
    "    ON embedded_data AS InputTable \n",
    "USING\n",
    "    IdColumn('comment_id') \n",
    "    TargetColumns('[1:49]') \n",
    "    NumClusters(8)\n",
    "    StopThreshold(0.0295) \n",
    "MaxIterNum(10)\n",
    ")AS dt;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Step 3 - Find the ideal number of Customer Segments</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>A simple plot will show the \"elbow\" point indicating an ideal number of clusters or segments.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = _\n",
    "res.DataFrame().set_index('K').plot(kind = 'line', figsize = (8,8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Conclusion</b></p>\n",
    "\n",
    "<p style = 'font-size:16px;font-family:Arial;color:#00233C'>From our simple demonstration above, we can see how data practitioners can rapidly derive powerful and unique predictive features by combining the latest AI with traditional Machine Learning <b>at scale</b>.  Furthermore, we can easily operationalize this process by combining this vector embedding and segmentation into traditional Customer 360, analytics, or additional predicitve modeling tasks - all on the same platform.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<p style = 'font-size:20px;font-family:Arial;color:#00233C'><b>Cleanup</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql DROP TABLE embedded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
